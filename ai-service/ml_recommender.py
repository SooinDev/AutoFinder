# ml_recommender.py (NaN ì²˜ë¦¬ ê°•í™” ë²„ì „)
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.impute import SimpleImputer  # ê²°ì¸¡ê°’ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
import pandas as pd
import numpy as np
import joblib

class MLCarRecommender:
    def __init__(self):
        self.model = GradientBoostingRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=6,
            random_state=42
        )
        self.scaler = StandardScaler()
        self.imputer = SimpleImputer(strategy='median')  # ê²°ì¸¡ê°’ ì²˜ë¦¬ê¸° ì¶”ê°€
        self.label_encoders = {}
        self.feature_columns = []
        self.is_trained = False

    def prepare_training_data(self, cars_df, favorites_df):
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        print(f"ì›ë³¸ ì°¨ëŸ‰ ë°ì´í„° í¬ê¸°: {cars_df.shape}")
        print(f"ì›ë³¸ ì¦ê²¨ì°¾ê¸° ë°ì´í„° í¬ê¸°: {favorites_df.shape}")

        # ë°ì´í„° ì •ì œ
        cars_df_clean = self.clean_car_data(cars_df)
        print(f"ì •ì œëœ ì°¨ëŸ‰ ë°ì´í„° í¬ê¸°: {cars_df_clean.shape}")

        # ê¸ì •ì  ìƒ˜í”Œ (ì¦ê²¨ì°¾ê¸°í•œ ì°¨ëŸ‰) - í‰ì  4-5
        positive_samples = []
        for _, fav in favorites_df.iterrows():
            car_data = cars_df_clean[cars_df_clean['id'] == fav['car_id']]
            if not car_data.empty:
                sample = car_data.iloc[0].copy()
                sample['user_id'] = fav['user_id']
                sample['rating'] = np.random.uniform(4.0, 5.0)  # ë†’ì€ í‰ì 
                positive_samples.append(sample)

        print(f"ê¸ì •ì  ìƒ˜í”Œ ìˆ˜: {len(positive_samples)}")

        # ë¶€ì •ì  ìƒ˜í”Œ (ëœë¤ ì°¨ëŸ‰) - í‰ì  1-3
        negative_samples = []
        users = favorites_df['user_id'].unique()
        favorited_cars = set(favorites_df['car_id'].unique())

        for user_id in users:
            # ê° ì‚¬ìš©ìë§ˆë‹¤ ì¦ê²¨ì°¾ê¸°í•˜ì§€ ì•Šì€ ì°¨ëŸ‰ ì¤‘ ëœë¤ ìƒ˜í”Œë§
            non_favorited = cars_df_clean[~cars_df_clean['id'].isin(favorited_cars)]
            if len(non_favorited) > 0:
                n_samples = min(3, len(non_favorited))  # ìƒ˜í”Œ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ ê· í˜• ë§ì¶”ê¸°
                sampled_cars = non_favorited.sample(n=n_samples, random_state=42)

                for _, car in sampled_cars.iterrows():
                    sample = car.copy()
                    sample['user_id'] = user_id
                    sample['rating'] = np.random.uniform(1.0, 3.0)  # ë‚®ì€ í‰ì 
                    negative_samples.append(sample)

        print(f"ë¶€ì •ì  ìƒ˜í”Œ ìˆ˜: {len(negative_samples)}")

        # ì „ì²´ í•™ìŠµ ë°ì´í„° ìƒì„±
        all_samples = positive_samples + negative_samples
        training_df = pd.DataFrame(all_samples)

        # í•™ìŠµ ë°ì´í„°ë„ ì •ì œ
        training_df = self.clean_car_data(training_df)

        print(f"ìµœì¢… í•™ìŠµ ë°ì´í„° í¬ê¸°: {training_df.shape}")
        print(f"í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: ê¸ì • ìƒ˜í”Œ {len(positive_samples)}ê°œ, ë¶€ì • ìƒ˜í”Œ {len(negative_samples)}ê°œ")

        return training_df

    def clean_car_data(self, df):
        """ì°¨ëŸ‰ ë°ì´í„° ì •ì œ"""
        df_clean = df.copy()

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
        if 'id' not in df_clean.columns:
            df_clean['id'] = range(len(df_clean))

        # ê¸°ë³¸ê°’ìœ¼ë¡œ ê²°ì¸¡ê°’ ì²˜ë¦¬
        default_values = {
            'model': 'ì•Œ ìˆ˜ ì—†ìŒ',
            'year': '2020',
            'price': 2000,
            'mileage': 50000,
            'fuel': 'ê°€ì†”ë¦°',
            'region': 'ì„œìš¸',
            'carType': 'ì¤‘í˜•ì°¨'
        }

        for col, default_val in default_values.items():
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].fillna(default_val)
            else:
                df_clean[col] = default_val

        # ìˆ˜ì¹˜í˜• ë°ì´í„° ë³€í™˜ ë° ì •ì œ
        df_clean['price'] = pd.to_numeric(df_clean['price'], errors='coerce')
        df_clean['mileage'] = pd.to_numeric(df_clean['mileage'], errors='coerce')

        # ì´ìƒê°’ ì²˜ë¦¬
        df_clean['price'] = df_clean['price'].clip(lower=100, upper=50000)  # 100ë§Œì› ~ 5ì–µì›
        df_clean['mileage'] = df_clean['mileage'].clip(lower=0, upper=500000)  # 0 ~ 50ë§Œkm

        # ë‹¤ì‹œ í•œë²ˆ ê²°ì¸¡ê°’ ì²˜ë¦¬
        df_clean['price'] = df_clean['price'].fillna(2000)
        df_clean['mileage'] = df_clean['mileage'].fillna(50000)

        # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
        df_clean['year_numeric'] = df_clean['year'].apply(self._extract_year)
        df_clean['age'] = 2024 - df_clean['year_numeric']
        df_clean['brand'] = df_clean['model'].apply(self._extract_brand)

        # ì—°ì‹ì´ ì´ìƒí•œ ê²½ìš° ì²˜ë¦¬
        df_clean['age'] = df_clean['age'].clip(lower=0, upper=50)

        return df_clean

    def engineer_features(self, df):
        """íŠ¹ì„± ê³µí•™ - NaN ì²˜ë¦¬ ê°•í™”"""
        features_df = df.copy()

        # ë°ì´í„° ì •ì œ ë¨¼ì € ìˆ˜í–‰
        features_df = self.clean_car_data(features_df)

        print("íŠ¹ì„± ê³µí•™ ì „ ë°ì´í„° í™•ì¸:")
        print(f"ë°ì´í„° í¬ê¸°: {features_df.shape}")
        print(f"ê²°ì¸¡ê°’ í™•ì¸:\n{features_df.isnull().sum()}")

        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_columns = ['brand', 'fuel', 'region', 'carType']
        for col in categorical_columns:
            if col in features_df.columns:
                # ê²°ì¸¡ê°’ì„ 'Unknown'ìœ¼ë¡œ ëŒ€ì²´
                features_df[col] = features_df[col].fillna('Unknown').astype(str)

                if col not in self.label_encoders:
                    self.label_encoders[col] = LabelEncoder()
                    features_df[f'{col}_encoded'] = self.label_encoders[col].fit_transform(features_df[col])
                else:
                    # í•™ìŠµ ì‹œ ë³´ì§€ ëª»í•œ ê°’ ì²˜ë¦¬
                    def safe_transform(x):
                        try:
                            return self.label_encoders[col].transform([str(x)])[0]
                        except ValueError:
                            # ìƒˆë¡œìš´ ê°’ì€ ê°€ì¥ ë¹ˆë²ˆí•œ ê°’ìœ¼ë¡œ ëŒ€ì²´
                            most_common = self.label_encoders[col].classes_[0]
                            return self.label_encoders[col].transform([most_common])[0]

                    features_df[f'{col}_encoded'] = features_df[col].apply(safe_transform)

        # ìˆ˜ì¹˜í˜• íŠ¹ì„± ì„ íƒ
        numerical_features = ['user_id', 'price', 'year_numeric', 'age', 'mileage']
        categorical_encoded = [f'{col}_encoded' for col in categorical_columns if col in features_df.columns]

        all_features = numerical_features + categorical_encoded

        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_features = [col for col in all_features if col in features_df.columns]

        # íŠ¹ì„± ë°ì´í„° ì¶”ì¶œ
        X = features_df[available_features].copy()

        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
        for col in X.columns:
            X[col] = pd.to_numeric(X[col], errors='coerce')

        # ê²°ì¸¡ê°’ ìµœì¢… ì²˜ë¦¬
        print("íŠ¹ì„± ì¶”ì¶œ í›„ ê²°ì¸¡ê°’ í™•ì¸:")
        print(X.isnull().sum())

        # SimpleImputerë¡œ ê²°ì¸¡ê°’ ì²˜ë¦¬
        if X.isnull().any().any():
            print("ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
            X_filled = pd.DataFrame(
                self.imputer.fit_transform(X),
                columns=X.columns,
                index=X.index
            )
        else:
            X_filled = X

        # ë¬´í•œê°’ ì²˜ë¦¬
        X_filled = X_filled.replace([np.inf, -np.inf], np.nan)
        X_filled = X_filled.fillna(0)

        # ìµœì¢… í™•ì¸
        print("ìµœì¢… íŠ¹ì„± ë°ì´í„°:")
        print(f"í¬ê¸°: {X_filled.shape}")
        print(f"ê²°ì¸¡ê°’: {X_filled.isnull().sum().sum()}")
        print(f"ë¬´í•œê°’: {np.isinf(X_filled.values).sum()}")

        self.feature_columns = available_features
        print(f"ì‚¬ìš©í•  íŠ¹ì„±: {self.feature_columns}")

        return X_filled

    def _extract_year(self, year_str):
        """ì—°ë„ ì¶”ì¶œ"""
        if pd.isna(year_str) or year_str == '':
            return 2020

        try:
            # ìˆ«ìë§Œ ì¶”ì¶œ
            digits = ''.join(filter(str.isdigit, str(year_str)))
            if not digits:
                return 2020

            if len(digits) >= 4:
                year = int(digits[:4])
                # í•©ë¦¬ì ì¸ ë²”ìœ„ í™•ì¸
                if 1990 <= year <= 2024:
                    return year
                else:
                    return 2020
            elif len(digits) == 2:
                year = int(digits)
                if year <= 24:
                    return 2000 + year
                else:
                    return 1900 + year
            else:
                return 2020

        except:
            return 2020

    def _extract_brand(self, model_str):
        """ë¸Œëœë“œ ì¶”ì¶œ"""
        if pd.isna(model_str) or model_str == '':
            return "ê¸°íƒ€"

        brands = ["í˜„ëŒ€", "ê¸°ì•„", "ì œë„¤ì‹œìŠ¤", "ë¥´ë…¸", "ì‰ë³´ë ˆ", "ìŒìš©", "BMW", "ë²¤ì¸ ", "ì•„ìš°ë””", "ë³¼ë³´"]
        model_str = str(model_str)

        for brand in brands:
            if brand in model_str:
                return brand

        # ì²« ë²ˆì§¸ ë‹¨ì–´ë¥¼ ë¸Œëœë“œë¡œ ì‚¬ìš©
        words = model_str.split()
        return words[0] if words else "ê¸°íƒ€"

    def train(self, cars_df, favorites_df):
        """ëª¨ë¸ í•™ìŠµ"""
        try:
            print("=== ML ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")

            print("1. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
            training_df = self.prepare_training_data(cars_df, favorites_df)

            if training_df.empty:
                print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False

            print("2. íŠ¹ì„± ê³µí•™ ìˆ˜í–‰ ì¤‘...")
            X = self.engineer_features(training_df)

            if 'rating' not in training_df.columns:
                print("âŒ í‰ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False

            y = training_df['rating'].copy()

            # y ê°’ë„ ì •ì œ
            y = pd.to_numeric(y, errors='coerce')
            y = y.fillna(3.0)  # ê¸°ë³¸ê°’ 3.0
            y = y.clip(lower=1.0, upper=5.0)  # 1-5 ë²”ìœ„ë¡œ ì œí•œ

            print(f"íŠ¹ì„± ë°ì´í„° í¬ê¸°: {X.shape}")
            print(f"íƒ€ê²Ÿ ë°ì´í„° í¬ê¸°: {y.shape}")
            print(f"íŠ¹ì„± ë°ì´í„° ê²°ì¸¡ê°’: {X.isnull().sum().sum()}")
            print(f"íƒ€ê²Ÿ ë°ì´í„° ê²°ì¸¡ê°’: {y.isnull().sum()}")

            # ìµœì†Œ í•™ìŠµ ë°ì´í„° í™•ì¸
            if len(X) < 5:
                print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 5ê°œ í•„ìš”.")
                return False

            # ì¸ë±ìŠ¤ ì •ë ¬
            X = X.reset_index(drop=True)
            y = y.reset_index(drop=True)

            print("3. ë°ì´í„° ë¶„í•  ì¤‘...")
            # ë°ì´í„° ë¶„í• 
            if len(X) > 10:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
            else:
                # ë°ì´í„°ê°€ ì ìœ¼ë©´ ì „ì²´ë¥¼ í•™ìŠµì— ì‚¬ìš©
                X_train, X_test = X, X
                y_train, y_test = y, y

            print("4. íŠ¹ì„± ì •ê·œí™” ì¤‘...")
            # íŠ¹ì„± ì •ê·œí™”
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)

            # ì •ê·œí™” í›„ì—ë„ í™•ì¸
            if np.isnan(X_train_scaled).any() or np.isinf(X_train_scaled).any():
                print("âŒ ì •ê·œí™” í›„ì—ë„ NaN ë˜ëŠ” ë¬´í•œê°’ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
                print("NaN ê°œìˆ˜:", np.isnan(X_train_scaled).sum())
                print("ë¬´í•œê°’ ê°œìˆ˜:", np.isinf(X_train_scaled).sum())
                return False

            print("5. ëª¨ë¸ í•™ìŠµ ì¤‘...")
            self.model.fit(X_train_scaled, y_train)

            print("6. ëª¨ë¸ í‰ê°€ ì¤‘...")
            # ëª¨ë¸ í‰ê°€
            train_pred = self.model.predict(X_train_scaled)
            test_pred = self.model.predict(X_test_scaled)

            train_mse = mean_squared_error(y_train, train_pred)
            test_mse = mean_squared_error(y_test, test_pred)

            print(f"âœ… í›ˆë ¨ MSE: {train_mse:.4f}")
            print(f"âœ… í…ŒìŠ¤íŠ¸ MSE: {test_mse:.4f}")

            # íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥
            if hasattr(self.model, 'feature_importances_'):
                feature_importance = pd.DataFrame({
                    'feature': self.feature_columns,
                    'importance': self.model.feature_importances_
                }).sort_values('importance', ascending=False)

                print("\nğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ TOP 5:")
                print(feature_importance.head().to_string(index=False))

            self.is_trained = True
            print("ğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            return True

        except Exception as e:
            print(f"âŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def predict_user_preferences(self, user_id, candidate_cars_df):
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # í›„ë³´ ì°¨ëŸ‰ì— ì‚¬ìš©ì ID ì¶”ê°€
        candidates = candidate_cars_df.copy()
        candidates['user_id'] = user_id

        # íŠ¹ì„± ì¶”ì¶œ
        X = self.engineer_features(candidates)
        X_scaled = self.scaler.transform(X)

        # ì˜ˆì¸¡
        predictions = self.model.predict(X_scaled)

        # ê²°ê³¼ ì •ë¦¬
        candidates['predicted_rating'] = predictions
        candidates = candidates.sort_values('predicted_rating', ascending=False)

        return candidates

    def get_recommendations(self, user_id, cars_df, exclude_ids=None, top_k=10):
        """ì¶”ì²œ ìƒì„±"""
        if exclude_ids is None:
            exclude_ids = []

        # í›„ë³´ ì°¨ëŸ‰ í•„í„°ë§
        candidate_cars = cars_df[~cars_df['id'].isin(exclude_ids)].copy()

        if candidate_cars.empty:
            return []

        try:
            # ì˜ˆì¸¡
            predictions = self.predict_user_preferences(user_id, candidate_cars)

            # ìƒìœ„ Kê°œ ì„ íƒ
            top_recommendations = predictions.head(top_k)

            # ê²°ê³¼ í¬ë§·
            recommendations = []
            for _, row in top_recommendations.iterrows():
                recommendations.append({
                    'car': {
                        'id': int(row['id']),
                        'model': str(row.get('model', '')),
                        'year': str(row.get('year', '')),
                        'price': int(row.get('price', 0)),
                        'fuel': str(row.get('fuel', '')),
                        'region': str(row.get('region', '')),
                        'brand': str(row.get('brand', '')),
                        'carType': str(row.get('carType', ''))
                    },
                    'similarity_score': float(min(max(row['predicted_rating'] / 5.0, 0), 1)),
                    'recommendation_reason': f"ML ì˜ˆì¸¡ ì ìˆ˜: {row['predicted_rating']:.2f}/5.0"
                })

            return recommendations

        except Exception as e:
            print(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    def save_model(self, path):
        """ëª¨ë¸ ì €ì¥"""
        try:
            model_data = {
                'model': self.model,
                'scaler': self.scaler,
                'imputer': self.imputer,
                'label_encoders': self.label_encoders,
                'feature_columns': self.feature_columns,
                'is_trained': self.is_trained
            }
            joblib.dump(model_data, path)
            print(f"ğŸ’¾ ëª¨ë¸ì´ {path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_model(self, path):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            model_data = joblib.load(path)
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.imputer = model_data.get('imputer', SimpleImputer(strategy='median'))
            self.label_encoders = model_data['label_encoders']
            self.feature_columns = model_data['feature_columns']
            self.is_trained = model_data['is_trained']
            print(f"ğŸ“‚ ëª¨ë¸ì´ {path}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False